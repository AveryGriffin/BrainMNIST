{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import copy\n",
    "\n",
    "from numpy.fft import fft\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_data(data_array, pad_type):\n",
    "    max_length = get_max_length(data_array)\n",
    "    \n",
    "    for sample in range(len(data_array)):\n",
    "        data_array[sample] = np.pad(data_array[sample], (0, max_length-len(data_array[sample])), pad_type)\n",
    "        \n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(data_array):\n",
    "    max_length = 0\n",
    "    for sample in range(len(data_array)):\n",
    "        if len(data_array[sample]) > max_length:\n",
    "            max_length = len(data_array[sample])\n",
    "            \n",
    "    print(\"MAX LENGTH: \", max_length)\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data(dataset, Hz_colname, filter_bottom, filter_top):\n",
    "    filter_ = dataset[(dataset[Hz_colname] >= filter_bottom) & (dataset[Hz_colname] <= filter_top)]\n",
    "    print(\"lengths of dataset\", len(dataset),\n",
    "          \"length of filtered set:\", len(filter_),\n",
    "          \"length that was filtered out:\", len(dataset) - len(filter_))\n",
    "    print(\"Percent of Original Data Retained:\", round(len(filter_) / len(dataset) * 100, 2), \"%\")\n",
    "    return filter_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_signal(signal, cropLength):\n",
    "    signal_cropped = np.empty((len(signal)), dtype=object)\n",
    "    for n in range(len(signal_cropped)):\n",
    "        signal_cropped[n] = np.array(signal[n][:cropLength])\n",
    "    return signal_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dtype(data):\n",
    "    print(\"Previous Dtype:\", data.dtype)\n",
    "    if data.dtype == 'O':\n",
    "        data = np.vstack(data[:]).astype(np.float)\n",
    "        print(\"Fixed. New Dtye:\", data.dtype)\n",
    "        return data\n",
    "    else:\n",
    "        return \"Not Object Type:\", data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_x(x_, channels, length):\n",
    "    reshaped_x = np.empty((x_.shape[0], channels, length))\n",
    "    for event in range(len(x_)):\n",
    "        for channel in range(len(x_[0])):\n",
    "            reshaped_x[event][channel] = grouped_x[event][channel]\n",
    "    \n",
    "    reshaped_x = np.reshape(reshaped_x, (reshaped_x.shape[0], reshaped_x.shape[1]*reshaped_x.shape[2]))\n",
    "    return reshaped_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fft(signalData):\n",
    "    x_fourier, x_cropped_fourier = build_empty_array(signalData)\n",
    "    \n",
    "    for observation in range(len(signalData)):\n",
    "        x_fourier[observation] = fft(signalData[observation])\n",
    "        \n",
    "        full_length = len(x_fourier[observation])\n",
    "        \n",
    "        x_cropped_fourier[observation] = (2/full_length)*x_fourier[observation]  # [:full_length//2]\n",
    "\n",
    "    return x_cropped_fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_empty_array(signalData):\n",
    "    x_fourier = np.empty((signalData.shape[0]), dtype=object)\n",
    "    x_cropped_fourier = np.empty((signalData.shape[0]), dtype=object)\n",
    "    \n",
    "    print(x_fourier.shape, x_cropped_fourier.shape)\n",
    "    return x_fourier, x_cropped_fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(x_prescaled):\n",
    "    for feature in range(x_prescaled.T.shape[0]):\n",
    "        feature_min = min(x_prescaled.T[feature])\n",
    "        feature_max = max(x_prescaled.T[feature])\n",
    "        feature_range = feature_max - feature_min\n",
    "        x_prescaled.T[feature] = ( x_prescaled.T[feature] - feature_min ) / feature_range\n",
    "    return x_prescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This converts the string signal data into an array and then converts each string element into a float element.\n",
    "def string_to_float(stringed_signal_data):\n",
    "    \n",
    "    float_signal_data = np.empty((len(stringed_signal_data)), dtype=object)\n",
    "    \n",
    "    for n in range(len(float_signal_data)):\n",
    "        single_signal_observation = stringed_signal_data[n][6].split(\",\")\n",
    "        single_signal_observation = [float(i) for i in single_signal_observation]        \n",
    "        float_signal_data[n] = single_signal_observation\n",
    "        \n",
    "    print(\"The Shape of the Array we created after converting to floats:\", float_signal_data.shape)\n",
    "    print(\"The Shape of the Original Array of Stringed Signal Data:     \", stringed_signal_data[:,6].shape)\n",
    "\n",
    "    return float_signal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_signal(signal_float):\n",
    "    signal_array = np.empty((len(signal_float)), dtype=object)\n",
    "    for n in range(len(signal_array)):\n",
    "        signal_array[n] = np.array(signal_float[n])\n",
    "    return signal_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_data = pd.read_csv(\"C:/Users/Avery/Anaconda3/envs/mnistbrain/IN.txt\", sep=\"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_data.columns = [\"ID\", \"Event ID\", \"Device\", \"Channel\", \"Label\", \"HzCaptured\", \"Signal\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data by Hz - OPTIONAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowerBound = 248\n",
    "#upperBound =  260"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths of dataset 65250 length of filtered set: 58010 length that was filtered out: 7240\n",
      "Percent of Original Data Retained: 88.9 %\n"
     ]
    }
   ],
   "source": [
    "#IN_data = filter_data(IN_data, \"HzCaptured\", lowerBound, upperBound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Signal Data to Arrays of Floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58010, 7)\n"
     ]
    }
   ],
   "source": [
    "IN_data_array = IN_data.to_numpy()\n",
    "print(IN_data_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shape of the Array we created after converting to floats: (58010,)\n",
      "The Shape of the Original Array of Stringed Signal Data:      (58010,)\n"
     ]
    }
   ],
   "source": [
    "IN_signal_float = string_to_float(IN_data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del IN_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop Data - DO THIS IF NOT PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN_signal_float = crop_signal(signal=IN_signal_float, cropLength=lowerBound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arraying the Signal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is needed if padding, doesn't affect results if not padding\n",
    "IN_signal_array = array_signal(IN_signal_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "del IN_signal_float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_x = scale_features(IN_signal_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del IN_signal_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_y = IN_data_array[:,4]\n",
    "IN_y = IN_y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del IN_data_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novel-Method Loop - IF PADDING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = ['constant', 'minimum', 'maximum', 'mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for pad in pads:\\n    print(\"Pad Type: \", pad)\\n    \\n    IN_padded = pad_data(scaled_x, pad)\\n    \\n    IN_fourier = apply_fft(IN_padded)\\n    del IN_padded\\n    \\n    IN_fourier = fix_dtype(IN_fourier)\\n        \\n    X_train, X_test, y_train, y_test = train_test_split(IN_fourier, IN_y, test_size=0.20)\\n    print(\"X_train, X_test, y_train, y_test Shapes: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\\n    \\n    pca = PCA(n_components=20)\\n    pricinple_components = pca.fit(X_train)\\n    PCA_X_train = pca.transform(X_train)\\n    PCA_X_test = pca.transform(X_test)\\n    print(\"Explained Variance Ratio:\\n\", 100*pca.explained_variance_ratio_)\\n    \\n    error = []\\n    for i in range(1, 5):\\n        print(\"Neighbors:\", i)\\n        knn = KNeighborsClassifier(n_neighbors=i)\\n        knn.fit(PCA_X_train, y_train)\\n        pred_i = knn.predict(PCA_X_test)\\n        error.append(np.mean(pred_i != y_test))\\n        print(\"Classification Report:\\n\", classification_report(y_test, pred_i))'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for pad in pads:\n",
    "    print(\"Pad Type: \", pad)\n",
    "    \n",
    "    IN_padded = pad_data(scaled_x, pad)\n",
    "    \n",
    "    IN_fourier = apply_fft(IN_padded)\n",
    "    del IN_padded\n",
    "    \n",
    "    IN_fourier = fix_dtype(IN_fourier)\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(IN_fourier, IN_y, test_size=0.20)\n",
    "    print(\"X_train, X_test, y_train, y_test Shapes: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    \n",
    "    pca = PCA(n_components=20)\n",
    "    pricinple_components = pca.fit(X_train)\n",
    "    PCA_X_train = pca.transform(X_train)\n",
    "    PCA_X_test = pca.transform(X_test)\n",
    "    print(\"Explained Variance Ratio:\\n\", 100*pca.explained_variance_ratio_)\n",
    "    \n",
    "    error = []\n",
    "    for i in range(1, 5):\n",
    "        print(\"Neighbors:\", i)\n",
    "        knn = KNeighborsClassifier(n_neighbors=i)\n",
    "        knn.fit(PCA_X_train, y_train)\n",
    "        pred_i = knn.predict(PCA_X_test)\n",
    "        error.append(np.mean(pred_i != y_test))\n",
    "        print(\"Classification Report:\\n\", classification_report(y_test, pred_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Novel-Method Loop - IF NOT PADDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Not Padding ---\n",
      "(58010,) (58010,)\n",
      "Previous Dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Avery\\Anaconda3\\envs\\mnistbrain\\lib\\site-packages\\ipykernel_launcher.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed. New Dtye: float64\n",
      "X_train, X_test, y_train, y_test Shapes:  (46408, 248) (11602, 248) (46408,) (11602,)\n",
      "Explained Variance Ratio:\n",
      " [23.12624896 13.20681327  9.72873594  6.77748426  3.43223904  2.38579587\n",
      "  1.89081628  1.42913086  1.29003336  1.12257301  0.9680974   0.93083403\n",
      "  0.85337429  0.82207197  0.78164342  0.72550031  0.71734524  0.68077264\n",
      "  0.64665494  0.62363394]\n",
      "Neighbors: 1\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.17      0.17      1158\n",
      "           1       0.16      0.16      0.16      1174\n",
      "           2       0.16      0.17      0.17      1174\n",
      "           3       0.20      0.20      0.20      1179\n",
      "           4       0.17      0.18      0.17      1122\n",
      "           5       0.20      0.20      0.20      1133\n",
      "           6       0.18      0.18      0.18      1141\n",
      "           7       0.18      0.17      0.18      1146\n",
      "           8       0.21      0.20      0.20      1175\n",
      "           9       0.20      0.19      0.19      1200\n",
      "\n",
      "    accuracy                           0.18     11602\n",
      "   macro avg       0.18      0.18      0.18     11602\n",
      "weighted avg       0.18      0.18      0.18     11602\n",
      "\n",
      "Neighbors: 2\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.27      0.19      1158\n",
      "           1       0.14      0.25      0.18      1174\n",
      "           2       0.15      0.23      0.19      1174\n",
      "           3       0.18      0.23      0.21      1179\n",
      "           4       0.14      0.16      0.15      1122\n",
      "           5       0.19      0.16      0.17      1133\n",
      "           6       0.17      0.12      0.14      1141\n",
      "           7       0.16      0.08      0.11      1146\n",
      "           8       0.23      0.07      0.11      1175\n",
      "           9       0.40      0.05      0.09      1200\n",
      "\n",
      "    accuracy                           0.16     11602\n",
      "   macro avg       0.19      0.16      0.15     11602\n",
      "weighted avg       0.19      0.16      0.15     11602\n",
      "\n",
      "Neighbors: 3\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.30      0.18      1158\n",
      "           1       0.13      0.27      0.18      1174\n",
      "           2       0.16      0.24      0.19      1174\n",
      "           3       0.18      0.21      0.20      1179\n",
      "           4       0.15      0.13      0.14      1122\n",
      "           5       0.20      0.13      0.15      1133\n",
      "           6       0.21      0.10      0.14      1141\n",
      "           7       0.19      0.07      0.10      1146\n",
      "           8       0.22      0.06      0.10      1175\n",
      "           9       0.25      0.08      0.12      1200\n",
      "\n",
      "    accuracy                           0.16     11602\n",
      "   macro avg       0.18      0.16      0.15     11602\n",
      "weighted avg       0.18      0.16      0.15     11602\n",
      "\n",
      "Neighbors: 4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.31      0.18      1158\n",
      "           1       0.13      0.26      0.18      1174\n",
      "           2       0.15      0.19      0.17      1174\n",
      "           3       0.18      0.17      0.17      1179\n",
      "           4       0.15      0.12      0.13      1122\n",
      "           5       0.20      0.12      0.15      1133\n",
      "           6       0.19      0.10      0.14      1141\n",
      "           7       0.18      0.09      0.12      1146\n",
      "           8       0.20      0.09      0.12      1175\n",
      "           9       0.22      0.11      0.15      1200\n",
      "\n",
      "    accuracy                           0.16     11602\n",
      "   macro avg       0.17      0.16      0.15     11602\n",
      "weighted avg       0.17      0.16      0.15     11602\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"print(\"--- Not Padding ---\")\n",
    "\n",
    "IN_fourier = apply_fft(scaled_x)\n",
    "\n",
    "IN_fourier = fix_dtype(IN_fourier)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(IN_fourier, IN_y, test_size=0.20)\n",
    "print(\"X_train, X_test, y_train, y_test Shapes: \", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "pricinple_components = pca.fit(X_train)\n",
    "PCA_X_train = pca.transform(X_train)\n",
    "PCA_X_test = pca.transform(X_test)\n",
    "print(\"Explained Variance Ratio:\\n\", 100*pca.explained_variance_ratio_)\n",
    "\n",
    "error = []\n",
    "for i in range(1, 5):\n",
    "    print(\"Neighbors:\", i)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(PCA_X_train, y_train)\n",
    "    pred_i = knn.predict(PCA_X_test)\n",
    "    error.append(np.mean(pred_i != y_test))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, pred_i))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
